{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5312b152",
   "metadata": {},
   "source": [
    "This one did not finish due to the start of the selection alone not finishing after hours if I remember correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e2389",
   "metadata": {},
   "source": [
    "# Imports, data class and other helping methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1186e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee7882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now offers a shitty way to encode months\n",
    "#\n",
    "# Loads and prepares the data.\n",
    "# Data can be accessed over class variables: train_input_FOCI, train_target_FOCI, validation_input_FOCI...\n",
    "# Unprocessed data is saved. When seq_length or feature_list are None, they are not used.\n",
    "# Data is processed to have 0 mean and 1 std.\n",
    "# possible_features variable contains list with all feature names, even those that have not been selected.\n",
    "# For lead_time = 0, the sequences currently DO NOT contain previous prec_sahel values.\n",
    "# flatten_seq = False means that each sample consits of the arrays for each time step (e.g. [t1, t2, ...])\n",
    "# flatten_seq = True means that each sample contains all the values of the time steps. (array containing values vs array containing arrays of values)\n",
    "# month_encoding one of ['normal', 'one_hot', 'one_hot_scaled']\n",
    "class Data:\n",
    "  # Split = [train,validation, test], lead_time >= 0, seq_length > 0 or None, feature_list None or list of feature names\n",
    "  def __init__(self, split = [0.8, 0.1, 0.1], lead_time = 0, seq_length=None, flatten_seq=False, feature_list=None, month_encoding='normal'):\n",
    "    # Variables\n",
    "    self.scale_one_hot = False\n",
    "    self.possible_features = [] # Filled later on to track all possible features before selection\n",
    "    self.current_features = [] # Filled later to track selected features\n",
    "    self.one_hot_column_names = [] # Filled later if one_hot_encode_months is set to true\n",
    "    self.__data_url = (\n",
    "    \"https://github.com/MarcoLandtHayen/climate_index_collection/\"\n",
    "    \"releases/download/v2023.03.29.1/climate_indices.csv\"\n",
    "    )\n",
    "    \n",
    "    # Set variables for month encoding setting\n",
    "    if month_encoding == 'normal':\n",
    "        one_hot_encode_months = False\n",
    "    elif month_encoding == 'one_hot':\n",
    "        one_hot_encode_months = True\n",
    "    elif month_encoding == 'one_hot_scaled':\n",
    "        one_hot_encode_months = True\n",
    "        self.scale_one_hot = True\n",
    "    else:\n",
    "        raise ValueError(\"month_encoding has to be one of: {} but was {}\".format(['normal', 'one_hot', 'one_hot_scaled'], month_encoding))\n",
    "\n",
    "    # Load the data\n",
    "    FOCI, CESM = self.__load_data()\n",
    "    \n",
    "    # Get one_hot encodings for months and then remove the month column then join them back together\n",
    "    # The one hot encoded columns will be normalised later.\n",
    "    if one_hot_encode_months:\n",
    "      one_hot_FOCI = pd.get_dummies(FOCI['month'], prefix='month')\n",
    "      one_hot_CESM = pd.get_dummies(CESM['month'], prefix='month')\n",
    "      self.one_hot_column_names = list(one_hot_FOCI.columns)  # Save one hot encoded column names to exclude from standarisation\n",
    "      FOCI = one_hot_FOCI.join(FOCI.drop('month',axis = 1))\n",
    "      CESM = one_hot_CESM.join(CESM.drop('month',axis = 1))\n",
    "\n",
    "\n",
    "    # Split into input and target\n",
    "    input_FOCI, target_FOCI = self.__get_input_target(FOCI, lead_time)\n",
    "    input_CESM, target_CESM = self.__get_input_target(CESM, lead_time)\n",
    "\n",
    "    # Save possible features that can be selected\n",
    "    self.possible_features = list(input_FOCI.columns)\n",
    "\n",
    "    # Select features if any are set\n",
    "    input_FOCI = input_FOCI if feature_list is None else input_FOCI[feature_list]\n",
    "    input_CESM = input_CESM if feature_list is None else input_CESM[feature_list]\n",
    "\n",
    "    # Save selected features\n",
    "    self.current_features = list(input_FOCI.columns)\n",
    "\n",
    "    # Split into train, validation and test, based on split percentage given\n",
    "    self.train_input_FOCI, self.validation_input_FOCI, self.test_input_FOCI = self.__get_train_validation_test(input_FOCI, split)\n",
    "    self.train_target_FOCI, self.validation_target_FOCI, self.test_target_FOCI = self.__get_train_validation_test(target_FOCI, split)\n",
    "\n",
    "    self.train_input_CESM, self.validation_input_CESM, self.test_input_CESM = self.__get_train_validation_test(input_CESM, split)\n",
    "    self.train_target_CESM, self.validation_target_CESM, self.test_target_CESM = self.__get_train_validation_test(target_CESM, split)\n",
    "\n",
    "    # Fit standardscaler on trainings data and then scale train, validation and test input with it to obtain 0 mean and 1 std\n",
    "    # Returned values are numpy arrays\n",
    "    self.train_input_FOCI, self.validation_input_FOCI, self.test_input_FOCI = self.__scale_data(self.train_input_FOCI, self.validation_input_FOCI, self.test_input_FOCI)\n",
    "    self.train_input_CESM, self.validation_input_CESM, self.test_input_CESM = self.__scale_data(self.train_input_CESM, self.validation_input_CESM, self.test_input_CESM)\n",
    "\n",
    "    # Do the same with the target data\n",
    "    self.train_target_FOCI, self.validation_target_FOCI, self.test_target_FOCI = self.__scale_data(self.train_target_FOCI, self.validation_target_FOCI, self.test_target_FOCI)\n",
    "    self.train_target_CESM, self.validation_target_CESM, self.test_target_CESM = self.__scale_data(self.train_target_CESM, self.validation_target_CESM, self.test_target_CESM)\n",
    "\n",
    "    # Turn target arrays into 1D arrays, reshape only if array actually exists\n",
    "    # otherwise an error would be thrown.\n",
    "    if len(self.train_target_FOCI) > 0:\n",
    "      self.train_target_FOCI = self.train_target_FOCI.reshape(-1)\n",
    "      self.train_target_CESM = self.train_target_CESM.reshape(-1)\n",
    "    if len(self.validation_target_FOCI) > 0:\n",
    "      self.validation_target_FOCI = self.validation_target_FOCI.reshape(-1)\n",
    "      self.validation_target_CESM = self.validation_target_CESM.reshape(-1)\n",
    "    if len(self.test_target_FOCI) > 0:\n",
    "      self.test_target_FOCI = self.test_target_FOCI.reshape(-1)\n",
    "      self.test_target_CESM = self.test_target_CESM.reshape(-1)\n",
    "\n",
    "    # Turn data into sequences consisting of seq_length timesteps\n",
    "    if seq_length is not None:\n",
    "      # Check for valid seq_length\n",
    "      if seq_length <= 0:\n",
    "        raise ValueError('seq_length has to be an integer > 0 or None but is{}'.format(seq_length))\n",
    "\n",
    "      # Train FOCI\n",
    "      if len(self.train_input_FOCI) > 0:\n",
    "        self.train_input_FOCI, self.train_target_FOCI = self.__into_sequence(self.train_input_FOCI, self.train_target_FOCI, seq_length, flatten_seq)\n",
    "      # Validation FOCI\n",
    "      if len(self.validation_input_FOCI) > 0:\n",
    "        self.validation_input_FOCI, self.validation_target_FOCI = self.__into_sequence(self.validation_input_FOCI, self.validation_target_FOCI, seq_length, flatten_seq)\n",
    "      # Test FOCI\n",
    "      if len(self.test_input_FOCI) > 0:\n",
    "        self.test_input_FOCI, self.test_target_FOCI = self.__into_sequence(self.test_input_FOCI, self.test_target_FOCI, seq_length, flatten_seq)\n",
    "      # Train CESM\n",
    "      if len(self.train_input_CESM) > 0:\n",
    "        self.train_input_CESM, self.train_target_CESM = self.__into_sequence(self.train_input_CESM, self.train_target_CESM, seq_length, flatten_seq)\n",
    "      # Validation CESM\n",
    "      if len(self.validation_input_CESM) > 0:\n",
    "        self.validation_input_CESM, self.validation_target_CESM = self.__into_sequence(self.validation_input_CESM, self.validation_target_CESM, seq_length, flatten_seq)\n",
    "      # Test CESM\n",
    "      if len(self.test_input_CESM) > 0:\n",
    "        self.test_input_CESM, self.test_target_CESM = self.__into_sequence(self.test_input_CESM, self.test_target_CESM, seq_length, flatten_seq)\n",
    "\n",
    "\n",
    "  # Loads the data from url or disk, returns FOCI, CESM as pandas dataframes.\n",
    "  def __load_data(self):\n",
    "\n",
    "    # Check if data exists on disk, if so load from disk, otherwise from url\n",
    "    if os.path.exists('C:\\\\Users\\\\Jannik\\\\climate_indices.csv'):\n",
    "      climind = pd.read_csv('C:\\\\Users\\\\Jannik\\\\climate_indices.csv')\n",
    "    else:\n",
    "      climind = pd.read_csv(self.__data_url)\n",
    "      # Save data to disk\n",
    "      climind.to_csv('C:\\\\Users\\\\Jannik\\\\climate_indices.csv', index=False)\n",
    "\n",
    "    # Split into FOCI and CESM and drop year\n",
    "    climind = climind.set_index([\"model\", \"year\", \"month\", \"index\"]).unstack(level=-1)[\"value\"]\n",
    "    FOCI = climind.loc[('FOCI')].reset_index().drop(columns=['year'])\n",
    "    CESM = climind.loc[('CESM')].reset_index().drop(columns=['year'])\n",
    "\n",
    "    # Return them\n",
    "    return FOCI, CESM\n",
    "\n",
    "  # Takes the FOCI or CESM pandas dataframe and returns the input and target\n",
    "  # Input and target depends on the lead_time, for lead_time >0 input contains\n",
    "  # PREC_SAHEL of the current time step, for lead_time = 0 it does not.\n",
    "  # lead_time determines how many months in advance the target is.\n",
    "  def __get_input_target(self, data, lead_time):\n",
    "    # Check if lead_time is vlaid\n",
    "    if lead_time < 0:\n",
    "      raise ValueError('lead_time has to have a value >= 0 but has value {}'.format(self.__lead_time))\n",
    "\n",
    "    # Split into target and input, input has to omit the last lead_time elements or there would be no target for them\n",
    "    target = data.loc[:,data.columns == 'PREC_SAHEL']\n",
    "    input = data.loc[:,data.columns != 'PREC_SAHEL'] if lead_time == 0 else data[:-lead_time]\n",
    "\n",
    "    # Adjust target for lead_time if needed\n",
    "    if lead_time > 0:\n",
    "      target = target[lead_time:]\n",
    "\n",
    "    # Return input and target\n",
    "    return input, target\n",
    "\n",
    "  # Splits data based on the given split into train, validation and test\n",
    "  # split = [train, validation, test] as decimal indicating percentage\n",
    "  def __get_train_validation_test(self, data, split):\n",
    "    # Check if split is valid\n",
    "    if sum(split) != 1 or split[0] <= 0 or any(i < 0 for i in split):\n",
    "      raise ValueError('Invalid split has been passed. Values can be negative, have to sum up to 1 and train has to be > 0')\n",
    "\n",
    "    # Get number of samples for each split\n",
    "    n_train = int(split[0] * len(data))\n",
    "    n_val = int(split[1] * len(data))\n",
    "    n_test = int(split[2] * len(data))  # Only used to check if there is a test set\n",
    "\n",
    "    # Create the splits\n",
    "    train = data[:n_train] if n_train > 0 else []\n",
    "    val =  data[n_train:n_train+n_val] if n_val > 0 else []\n",
    "    test = data[n_train+n_val:] if n_test > 0 else []\n",
    "\n",
    "    # Return them\n",
    "    return train, val, test\n",
    "\n",
    "  # Scales the data so that the resulting data has mean of 0 and std of 1\n",
    "  def __scale_data(self, train, val, test):\n",
    "    scaler = None\n",
    "\n",
    "    # If scale_one_hot is set to false exclude the one hot encoded columns before using the Standardscaler\n",
    "    if self.scale_one_hot:\n",
    "      scaler = StandardScaler()\n",
    "    # Otherwise also scale them\n",
    "    else:\n",
    "      features = [feature_name for feature_name in train.columns if feature_name not in self.one_hot_column_names]\n",
    "      scaler = ColumnTransformer([('normal features', StandardScaler(), features)], remainder='passthrough')\n",
    "\n",
    "    # Fit on train data\n",
    "    scaler.fit(train)\n",
    "\n",
    "    # Transform train, val, test sets if they are non empty\n",
    "    scaled_train = scaler.transform(train) if len(train) > 0 else []\n",
    "    scaled_val = scaler.transform(val) if len(val) > 0 else []\n",
    "    scaled_test = scaler.transform(test) if len(test) > 0 else []\n",
    "\n",
    "    return scaled_train, scaled_val, scaled_test\n",
    "\n",
    "  # Turns input into a sequence consisting of seq_length time steps\n",
    "  # and selects i+seq_length-1 as the corresponding target index for the i'th sequence.\n",
    "  def __into_sequence(self, input, target, seq_length, flatten_seq):\n",
    "    input_seq = np.array([input[i:i+seq_length] for i in range(len(input)-seq_length)])\n",
    "    target_seq = np.array([target[i+seq_length-1] for i in range(len(target)-seq_length)])\n",
    "\n",
    "    # Flatten sample containing the sequences if wanted (sample = [t_0, t_1,...] with t_0 = [feature_1, feature_2,...])\n",
    "    if flatten_seq:\n",
    "      input_seq = [seq.reshape(-1) for seq in input_seq]\n",
    "\n",
    "    return input_seq, target_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84cd63",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3437ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably will already take way to long\n",
    "\n",
    "# Settings for inital grid search\n",
    "param_grid_rf = {\n",
    "    'random_state': [1],\n",
    "    'n_jobs': [10],\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10], \n",
    "    'min_samples_split': [2, 5, 10], \n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "# Left out for now: max_features, max_samples\n",
    "\n",
    "lead_time = 1\n",
    "seq_length = 12 # 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f94a32",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m grid_search_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(rf, param_grid_rf, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Perform Gridsearch\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mgrid_search_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_input_FOCI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_target_FOCI\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create data, RandomForestRegressor and GridSearchCV\n",
    "data = Data(split=[0.9, 0 , 0.1], flatten_seq=True, seq_length=12, lead_time=1)\n",
    "rf = RandomForestRegressor()\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform Gridsearch\n",
    "grid_search_rf.fit(data.train_input_FOCI, data.train_target_FOCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best settings and best (negative) mse\n",
    "best_settings = grid_search_rf.best_params_\n",
    "print('best settings: {}'.format(best_settings))\n",
    "print('neg_mean_squared_error: {}'.format(grid_search_rf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63339e4e",
   "metadata": {},
   "source": [
    "# Determine sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c088572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_seq_length(lead_time, settings, seq_lenghts):\n",
    "    best_length = None\n",
    "    best_corr = float('-inf')\n",
    "    \n",
    "    for seq in seq_lenghts:\n",
    "        data = Data(lead_time=lead_time, seq_length=seq, flatten_seq=True)\n",
    "        rf = RandomForestRegressor(**best_settings)\n",
    "        _, corr_foci = train_and_evaluate_randomforest(rf, data, calc_with='test', dataset='FOCI')\n",
    "        \n",
    "        if corr_foci > best_corr:\n",
    "            best_corr = corr_foci\n",
    "            best_length = seq\n",
    "    \n",
    "    print('best length is {} with corr of {}'.format(best_length, best_corr))\n",
    "    \n",
    "    return best_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_0 = determine_seq_length(lead_time=0, seq_lenghts=[4, 9, 12], settings=best_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff60f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_1 = determine_seq_length(lead_time=1, seq_lenghts=[12, 18, 24], settings=best_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eaa00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_3 = determine_seq_length(lead_time=3, seq_lenghts=[12, 22, 24], settings=best_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd310000",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_6 = determine_seq_length(lead_time=6, seq_lenghts=[12, 22, 24], settings=best_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d47307",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots feature importance, in case of seq_length > 1 the feature_importance for a feature is summed up over all time steps\n",
    "def plot_feature_importance(model, data):\n",
    "  feature_names = data.current_features\n",
    "\n",
    "  # Get feature importance with their corresponding names and sort in descending order.\n",
    "  # If there are multiple timesteps, sum a feature up over all time steps\n",
    "  foci_feature_importance = model.feature_importances_\n",
    "  per_feature = {}\n",
    "\n",
    "  for idx, value in enumerate(foci_feature_importance):\n",
    "    name = feature_names[idx % len(feature_names)]\n",
    "\n",
    "    if per_feature.get(name) is None:\n",
    "      per_feature[name] = value\n",
    "    else:\n",
    "      per_feature[name] += value\n",
    "\n",
    "  foci_feature_importance = [(name, value) for (name, value) in zip(per_feature.keys(), per_feature.values())]\n",
    "  foci_feature_importance = sorted(foci_feature_importance, key=lambda feature: feature[1], reverse=True)\n",
    "\n",
    "  # Plot them\n",
    "  plt.figure(figsize=(20, 3))\n",
    "  plt.bar([value for (value, name) in foci_feature_importance], [name for (value, name) in foci_feature_importance])\n",
    "  plt.xlabel('Feature')\n",
    "  plt.ylabel('Feature importance')\n",
    "  plt.xticks(rotation=90, ha='right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ddf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance_per_month(model, data):\n",
    "  foci_feature_importance = model.feature_importances_\n",
    "  monthly_feature_importance = []\n",
    "  num_features = len(data.current_features)\n",
    "\n",
    "  for i in range(0, len(foci_feature_importance), num_features):\n",
    "    monthly_feature_importance.append(sum(foci_feature_importance[i:i+num_features]))\n",
    "\n",
    "  months = [str(i) for i in range(len(monthly_feature_importance))]\n",
    "  months.reverse()  # Reverse them so that the month closest to the prediction has the label 0\n",
    "\n",
    "  plt.bar(months, monthly_feature_importance) # List representing months is reversed so that it represents how many months we are away from the current time step\n",
    "  plt.xlabel('Month')\n",
    "  plt.ylabel('Feature importance')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f809f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains random forest and returns mse on validation set (for FOCI)\n",
    "def train_and_evaluate_randomforest(model, data, calc_with='val', dataset='FOCI'):\n",
    "  # Select dataset\n",
    "  if dataset == 'FOCI':\n",
    "        # Trainset\n",
    "        train_input = data.train_input_FOCI\n",
    "        train_target = data.train_target_FOCI\n",
    "        # Test or validation set\n",
    "        if calc_with == 'val':\n",
    "            test_input = data.validation_input_FOCI\n",
    "            test_target = data.validation_target_FOCI\n",
    "        elif calc_with == 'test':\n",
    "            test_input = data.test_input_FOCI\n",
    "            test_target = data.test_target_FOCI\n",
    "  elif dataset == 'CESM':\n",
    "        # Trainset\n",
    "        train_input = data.train_input_CESM\n",
    "        train_target = data.train_target_CESM\n",
    "        # Test or validation set\n",
    "        if calc_with == 'val':\n",
    "            test_input = data.validation_input_CESM\n",
    "            test_target = data.validation_target_CESM\n",
    "        elif calc_with == 'test':\n",
    "            test_input = data.test_input_CESM\n",
    "            test_target = data.test_target_CESM    \n",
    "  # Train the model\n",
    "  model.fit(train_input, train_target)\n",
    "  predicted = model.predict(test_input)\n",
    "  mse = mean_squared_error(test_target, predicted)\n",
    "  corr = np.corrcoef(test_target, predicted)[0,1]\n",
    "\n",
    "  return mse, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2430ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a random forest model and an instance of the data class, returns (name, value) pairs representing\n",
    "# the feature importance for all features.\n",
    "def get_total_feature_ranking(model, data, descending=True):\n",
    "  feature_importances = model.feature_importances_\n",
    "  feature_names = data.current_features\n",
    "  per_feature = {}\n",
    "\n",
    "  for idx, value in enumerate(feature_importances):\n",
    "    name = feature_names[idx % len(feature_names)]\n",
    "    per_feature[name] = value if per_feature.get(name) is None else per_feature[name] + value\n",
    "\n",
    "  feature_ranking = [(name, value) for (name, value) in zip(per_feature.keys(), per_feature.values())]\n",
    "  feature_ranking = sorted(feature_ranking, key=lambda feature: feature[1], reverse=descending)\n",
    "\n",
    "  return feature_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafcedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(lead_time=1, seq_length=12, settings):\n",
    "    # Train initial model and get feature ranking\n",
    "    data = Data(split=[0.8, 0.1, 0.1], flatten_seq=True, seq_length=seq_length, lead_time=lead_time)\n",
    "    init_model = RandomForestRegressor(**settings)\n",
    "    _, init_corr = train_and_evaluate_randomforest(init_model, data)\n",
    "    feature_ranking = get_total_feature_ranking(init_model, data)\n",
    "    \n",
    "    # Set highest corrCoef found so far and best model\n",
    "    max_corr = float('-inf')\n",
    "    best_model = None\n",
    "\n",
    "    # Perform forward selection\n",
    "    selection = []\n",
    "    for (name, value) in feature_ranking:\n",
    "\n",
    "        # Add new feature\n",
    "        selection.append(name)\n",
    "        data = Data(split=[0.8, 0.1, 0.1], flatten_seq=True, seq_length=seq_length, feature_list=selection, lead_time=lead_time)\n",
    "\n",
    "        # Train model with selected features\n",
    "        model = RandomForestRegressor(**settings)\n",
    "        _, corr =  train_and_evaluate_randomforest(model, data)\n",
    "        \n",
    "        # Performance check for correlation\n",
    "        if corr > max_corr:\n",
    "            best_model = model # Save model so we avoid retraining it for results\n",
    "            max_corr = corr\n",
    "        # If no improvement happened remove the feature again\n",
    "        else:\n",
    "            selection = selection[:-1]\n",
    "    \n",
    "    # Print out results\n",
    "    clear_output()\n",
    "    print('All feature performance: {}'.format(init_corr))\n",
    "    print('Selected feature performance: {}'.format(max_corr))\n",
    "    print('Selected features: {}'.format(selection))\n",
    "    \n",
    "    # Check whether selection is an improvement\n",
    "    if init_corr > max_corr:\n",
    "        print('\\nNo improvement found by selecting features, returning to using all features.')\n",
    "        selection = None\n",
    "    else:\n",
    "        plot_feature_importance_per_month(best_model, data)\n",
    "        plot_feature_importance(best_model, data)\n",
    "    \n",
    "    return selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba947af0",
   "metadata": {},
   "source": [
    "## Perform feature selection for every lead_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_lt0 = forward_selection(lead_time=0, seq_length=seq_length_0, best_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ca5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_lt1 = forward_selection(lead_time=1, seq_length=seq_length_1, best_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb80631",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_lt3 = forward_selection(lead_time=3, seq_length=seq_length_3, best_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_lt6 = forward_selection(lead_time=6, seq_length=seq_length_6, best_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d184ea1",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cbb5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_encoding(config, selected_features, seq_length, lead_time):\n",
    "  encoding_options = ['normal', 'one_hot', 'one_hot_scaled']\n",
    "  best_corr = float('-inf')\n",
    "  best_encoding = None\n",
    "  best_selection = None\n",
    "    \n",
    "  for encoding in encoding_options:\n",
    "    # Adjust feature selection if needed, one hot encoded data has month_1,...,month_12 instead of month\n",
    "    if encoding != 'normal' and selected_features != None and 'month' in selected_features:\n",
    "        selection = ['month_{}'.format(i) for i in range(1,13)] + selected_features\n",
    "        selection.remove('month')\n",
    "        \n",
    "    # Train model and get corr\n",
    "    data = Data(lead_time=lead_time, seq_length=seq_length, feature_list=selection, month_encoding=encoding)\n",
    "    model = RandomForestRegressor(**settings)\n",
    "    _, corr =  train_and_evaluate_randomforest(model, data)\n",
    "    \n",
    "    # Test if current encoding is an improvement\n",
    "    if corr > best_corr:\n",
    "        best_corr = corr\n",
    "        best_encoding = encoding\n",
    "        best_selection = selection\n",
    "    \n",
    "    # Print out information about current encoding\n",
    "    print('Encoding {} has CorrCoef of: {}'.format(encoding, corr))\n",
    "    \n",
    "  # Print results\n",
    "  print('\\nBest encoding is {} with {} CorrCoef'.format(best_encoding, best_corr))      \n",
    "        \n",
    "  # Return the best found encoding and selection\n",
    "  \n",
    "  return best_encoding, best_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_lt0, selection_lt0 = find_best_encoding(best_settings, selection_lt0, seq_length=seq_length_0, lead_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b0125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_lt1, selection_lt1 = find_best_encoding(best_settings, selection_lt1, seq_length=seq_length_1, lead_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64611684",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_lt3, selection_lt3 = find_best_encoding(best_settings, selection_lt3, seq_length=seq_length_3, lead_time=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_lt6, selection_lt6 = find_best_encoding(best_settings, selection_lt6, seq_length=seq_length_6, lead_time=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c64000c",
   "metadata": {},
   "source": [
    "# Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {'Name': [], 'lead time': [], 'MSE FOCI': [], 'MSE CESM': [], 'Corr FOCI': [], 'Corr CESM': []}\n",
    "name = 'RandomForest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d6116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about the model\n",
    "print('RandomForest for leadtime=0')\n",
    "print('Encoding: {}'.format(encoding_lt0))\n",
    "print('Feature selection: {}'.format(selection_lt0))\n",
    "print('Settings: {}'.format(best_settings))\n",
    "\n",
    "# Evaluate\n",
    "data = Data(lead_time=0, seq_length=seq_length_0, feature_list=selection_lt0, month_encoding=encoding_lt0)\n",
    "rf = RandomForestRegressor(**best_settings)\n",
    "\n",
    "mse_foci, corr_foci = train_and_evaluate_randomforest(model, data, calc_with='test', dataset='FOCI')\n",
    "mse_cesm, corr_cesm = train_and_evaluate_randomforest(model, data, calc_with='test', dataset='CESM')\n",
    "\n",
    "# Insert into dict\n",
    "final_dict['Name'].append(name)\n",
    "final_dict['lead time'].append(0)\n",
    "final_dict['MSE FOCI'].append(mse_foci)\n",
    "final_dict['MSE CESM'].append(mse_cesm)\n",
    "final_dict['Corr FOCI'].append(corr_foci)\n",
    "final_dict['Corr CESM'].append(corr_cesm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fc583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about the model\n",
    "print('RandomForest for leadtime=1')\n",
    "print('Encoding: {}'.format(encoding_lt1))\n",
    "print('Feature selection: {}'.format(selection_lt1))\n",
    "print('Settings: {}'.format(best_settings))\n",
    "\n",
    "# Evaluate\n",
    "data = Data(lead_time=1, seq_length=seq_length_1, feature_list=selection_lt1, month_encoding=encoding_lt1)\n",
    "rf = RandomForestRegressor(**best_settings)\n",
    "\n",
    "mse_foci, corr_foci = train_and_evaluate_randomforest(model, data, calc_with='test', dataset='FOCI')\n",
    "mse_cesm, corr_cesm = train_and_evaluate_randomforest(model, data, calc_with='test', dataset='CESM')\n",
    "\n",
    "# Insert into dict\n",
    "final_dict['Name'].append(name)\n",
    "final_dict['lead time'].append(1)\n",
    "final_dict['MSE FOCI'].append(mse_foci)\n",
    "final_dict['MSE CESM'].append(mse_cesm)\n",
    "final_dict['Corr FOCI'].append(corr_foci)\n",
    "final_dict['Corr CESM'].append(corr_cesm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about the model\n",
    "print('RandomForest for leadtime=3')\n",
    "print('Encoding: {}'.format(encoding_lt3))\n",
    "print('Feature selection: {}'.format(selection_lt3))\n",
    "print('Settings: {}'.format(best_settings))\n",
    "\n",
    "# Evaluate\n",
    "data = Data(lead_time=3, seq_length=seq_length_3, feature_list=selection_lt3, month_encoding=encoding_lt3)\n",
    "rf = RandomForestRegressor(**best_settings)\n",
    "\n",
    "mse_foci, corr_foci = train_and_evaluate_randomforest(model, data, calc_with='test', dataset='FOCI')\n",
    "mse_cesm, corr_cesm = train_and_evaluate_randomforest(model, data, calc_with='test', dataset='CESM')\n",
    "\n",
    "# Insert into dict\n",
    "final_dict['Name'].append(name)\n",
    "final_dict['lead time'].append(3)\n",
    "final_dict['MSE FOCI'].append(mse_foci)\n",
    "final_dict['MSE CESM'].append(mse_cesm)\n",
    "final_dict['Corr FOCI'].append(corr_foci)\n",
    "final_dict['Corr CESM'].append(corr_cesm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about the model\n",
    "print('RandomForest for leadtime=6')\n",
    "print('Encoding: {}'.format(encoding_lt6))\n",
    "print('Feature selection: {}'.format(selection_lt6))\n",
    "print('Settings: {}'.format(best_settings))\n",
    "\n",
    "# Evaluate\n",
    "data = Data(lead_time=6, seq_length=seq_length_6, feature_list=selection_lt6, month_encoding=encoding_lt6)\n",
    "rf = RandomForestRegressor(**best_settings)\n",
    "\n",
    "mse_foci, corr_foci = train_and_evaluate_randomforest(model, data, calc_with='test', dataset='FOCI')\n",
    "mse_cesm, corr_cesm = train_and_evaluate_randomforest(model, data, calc_with='test', dataset='CESM')\n",
    "\n",
    "# Insert into dict\n",
    "final_dict['Name'].append(name)\n",
    "final_dict['lead time'].append(6)\n",
    "final_dict['MSE FOCI'].append(mse_foci)\n",
    "final_dict['MSE CESM'].append(mse_cesm)\n",
    "final_dict['Corr FOCI'].append(corr_foci)\n",
    "final_dict['Corr CESM'].append(corr_cesm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.DataFrame(data=final_dict)\n",
    "display(final_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
